import tvm
from tvm import relay
import numpy as np
from tvm.contrib.download import download_testdata
from tvm.contrib import relay_viz
from graphviz import Digraph

# PyTorch imports
from datasets import load_dataset

import torch
import torchvision
from transformers import AutoImageProcessor, ResNetForImageClassification

from PIL import Image

# model_name: used to get model form pytorch
def GenerateComputationGraph(model_name):
    # model = model.eval()
    img_url = "https://github.com/dmlc/mxnet.js/blob/main/data/cat.png?raw=true"
    img_path = download_testdata(img_url, "cat.png", module="data")
    img = Image.open(img_path).resize((224, 224))

    # Preprocess the image and convert to tensor
    from torchvision import transforms

    my_preprocess = transforms.Compose(
        [
            transforms.Resize(256),
            transforms.CenterCrop(224),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
        ]
    )
    img = my_preprocess(img)
    img = np.expand_dims(img, 0)

    # dataset = load_dataset("huggingface/cats-image")
    # image = dataset["test"]["image"][0]

    # image_processor = AutoImageProcessor.from_pretrained("microsoft/resnet-50")
    model = ResNetForImageClassification.from_pretrained(model_name ,torchscript=True)

    # inputs = image_processor(image, return_tensors="pt")
    # m.build([None, 224, 224, 3])  # Batch input shape.
    input_shape = [1, 3, 224, 224]
    input_data = torch.randn(input_shape)

    # print(model)
    # tokens_tensor = torch.tensor([indexed_tokens])
    # segments_tensors = torch.tensor([segments_ids])
    model = torch.jit.trace(model, input_data).eval()
    # scripted_model = torch.jit.trace(model, input_data).eval()
    input_name = "input0"
    shape_list = [(input_name, img.shape)]
    mod, params = relay.frontend.from_pytorch(model, shape_list)
    return mod, params

def Old_GenerateComputationGraph(model_name):

    # Get image to use as input_infos for relay.frontend.from_pytorch (not sure if/how to omit this)
    # More info: https://tvm.apache.org/docs/how_to/compile_models/from_pytorch.html
    img_url = "https://github.com/dmlc/mxnet.js/blob/main/data/cat.png?raw=true"
    img_path = download_testdata(img_url, "cat.png", module="data")
    img = Image.open(img_path).resize((224, 224))

    # Preprocess the image and convert to tensor
    from torchvision import transforms

    my_preprocess = transforms.Compose(
        [
            transforms.Resize(256),
            transforms.CenterCrop(224),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
        ]
    )
    img = my_preprocess(img)
    img = np.expand_dims(img, 0)

    model = getattr(torchvision.models, model_name)(pretrained=True)
    model = model.eval()
    # model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)

    input_shape = [1, 3, 224, 224]
    input_data = torch.randn(input_shape)
    scripted_model = torch.jit.trace(model, input_data).eval()

    # Convert the PyTorch model to a Relay function
    input_name = "input0"
    shape_list = [(input_name, img.shape)]
    mod, params = relay.frontend.from_pytorch(scripted_model, shape_list)
    return mod, params

# model_name: used to save graph to file
# mod: computation graph generated by 
def VisualizeGraph(mod, model_name):
    # graphviz attributes
    graph_attr = {"color": "red"}
    node_attr = {"color": "blue"}
    edge_attr = {"color": "black"}

    # VizNode is passed to the callback.
    # We want to color NCHW conv2d nodes. Also give Var a different shape.
    def get_node_attr(node):
        if "nn.conv2d" in node.type_name and "NCHW" in node.detail:
            return {
                "fillcolor": "green",
                "style": "filled",
                "shape": "box",
            }
        if "Var" in node.type_name:
            return {"shape": "ellipse"}
        return {"shape": "box"}

    # Create plotter and pass it to viz. Then render the graph.
    dot_plotter = relay_viz.DotPlotter(
        graph_attr=graph_attr,
        node_attr=node_attr,
        edge_attr=edge_attr,
        get_node_attr=get_node_attr)

    viz = relay_viz.RelayVisualizer(
        mod,
        relay_param=params,
        plotter=dot_plotter,
        parser=relay_viz.DotVizParser())
    viz.render(model_name)

#, target, passes
def CompileModel(mod, params, model_name):
    target = tvm.target.Target("llvm", host="llvm")
    dev = tvm.cpu(0)
    # Apply pass using opt_level=3
    # with tvm.transform.PassContext(opt_level=3):
    #     lib = relay.build(mod, target=target, params=params)
    
    # Apply passes sequentially
    passes = [
            relay.transform.FoldConstant(),
            tvm.transform.PrintIR(),
            relay.transform.EliminateCommonSubexpr(),
            relay.transform.FuseOps(),
        ]
    seq = tvm.transform.Sequential(passes)

    mod1 = seq(mod)

    llvm_ir = tvm.build(mod1, target="llvm")

    # print(llvm_ir.get_source())
    with open(model_name+".ll", "w") as f:
        f.write(llvm_ir.get_source())
    
    # print(len(mod))
    # print("--------------------------------")
    # print(len(mod1))

    # performance measuring: https://tvm.apache.org/docs/tutorial/autotvm_relay_x86.html#compile-the-model-with-relay
    # compiling DL models: https://tvm.apache.org/docs/tutorial/relay_quick_start.html

if __name__ == '__main__':
    # Pytorch models
    # model_names = ['alexnet', 'convnext_base', 'convnext_large', 'convnext_small', 'convnext_tiny', 'deeplabv3_mobilenet_v3_large', 'deeplabv3_resnet101', 'deeplabv3_resnet50', 'densenet121', 'densenet161', 'densenet169', 'densenet201', 'efficientnet_b0', 'efficientnet_b1', 'efficientnet_b2', 'efficientnet_b3', 'efficientnet_b4', 'efficientnet_b5', 'efficientnet_b6', 'efficientnet_b7', 'efficientnet_v2_l', 'efficientnet_v2_m', 'efficientnet_v2_s', 'fasterrcnn_mobilenet_v3_large_320_fpn', 'fasterrcnn_mobilenet_v3_large_fpn', 'fasterrcnn_resnet50_fpn', 'fasterrcnn_resnet50_fpn_v2', 'fcn_resnet101', 'fcn_resnet50', 'fcos_resnet50_fpn', 'googlenet', 'inception_v3', 'keypointrcnn_resnet50_fpn', 'lraspp_mobilenet_v3_large', 'maskrcnn_resnet50_fpn', 'maskrcnn_resnet50_fpn_v2', 'maxvit_t', 'mc3_18', 'mnasnet0_5', 'mnasnet0_75', 'mnasnet1_0', 'mnasnet1_3', 'mobilenet_v2', 'mobilenet_v3_large', 'mobilenet_v3_small', 'mvit_v1_b', 'mvit_v2_s', 'quantized_googlenet', 'quantized_inception_v3', 'quantized_mobilenet_v2', 'quantized_mobilenet_v3_large', 'quantized_resnet18', 'quantized_resnet50', 'quantized_resnext101_32x8d', 'quantized_resnext101_64x4d', 'quantized_shufflenet_v2_x0_5', 'quantized_shufflenet_v2_x1_0', 'quantized_shufflenet_v2_x1_5', 'quantized_shufflenet_v2_x2_0', 'r2plus1d_18', 'r3d_18', 'raft_large', 'raft_small', 'regnet_x_16gf', 'regnet_x_1_6gf', 'regnet_x_32gf', 'regnet_x_3_2gf', 'regnet_x_400mf', 'regnet_x_800mf', 'regnet_x_8gf', 'regnet_y_128gf', 'regnet_y_16gf', 'regnet_y_1_6gf', 'regnet_y_32gf', 'regnet_y_3_2gf', 'regnet_y_400mf', 'regnet_y_800mf', 'regnet_y_8gf', 'resnet101', 'resnet152', 'resnet18', 'resnet34', 'resnet50', 'resnext101_32x8d', 'resnext101_64x4d', 'resnext50_32x4d', 'retinanet_resnet50_fpn', 'retinanet_resnet50_fpn_v2', 's3d', 'shufflenet_v2_x0_5', 'shufflenet_v2_x1_0', 'shufflenet_v2_x1_5', 'shufflenet_v2_x2_0', 'squeezenet1_0', 'squeezenet1_1', 'ssd300_vgg16', 'ssdlite320_mobilenet_v3_large', 'swin3d_b', 'swin3d_s', 'swin3d_t', 'swin_b', 'swin_s', 'swin_t', 'swin_v2_b', 'swin_v2_s', 'swin_v2_t', 'vgg11', 'vgg11_bn', 'vgg13', 'vgg13_bn', 'vgg16', 'vgg16_bn', 'vgg19', 'vgg19_bn', 'vit_b_16', 'vit_b_32', 'vit_h_14', 'vit_l_16', 'vit_l_32', 'wide_resnet101_2', 'wide_resnet50_2']
    # model_names = ['wide_resnet101_2', 'wide_resnet50_2']

    # Huggingface models
    model_names = ["microsoft/resnet-50", "fxmarty/resnet-tiny-beans"]
    for model_name in model_names:
        # Create output file that doesn't have a / in it
        output_file = model_name[model_name.rindex("/")+1:]

        mod, params = GenerateComputationGraph(model_name)
        VisualizeGraph(mod, output_file)
        CompileModel(mod, params, output_file)

    # for model_name in model_names:
    #     mod, params = GenerateComputationGraph(model_name)
    #     # VisualizeGraph(mod, model_name)
    #     CompileModel(mod, params, model_name)
# viz = relay_viz.RelayVisualizer(mod)
# viz.render()

# Compile the model
# target = tvm.target.Target("llvm", host="llvm")
# dev = tvm.cpu(0)
# with tvm.transform.PassContext(opt_level=3):
#     lib = relay.build(mod, target=target, params=params)
